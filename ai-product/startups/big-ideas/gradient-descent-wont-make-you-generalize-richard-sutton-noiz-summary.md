# Gradient Descent Won’t Make You Generalize (Richard Sutton) — Notes

Summary for: https://youtu.be/_chDKAlIdAU  
Generated from transcript tooling (Noiz): https://noiz.io/tools/youtube-summary  
Status: **To verify**

## Generalization vs. Solution Finding (Claims)

- Gradient descent is framed as finding solutions to seen problems, but not inherently promoting positive generalization to new problems/states without algorithmic design that explicitly favors it. [Unverified]
- “Finding the only solution” is framed as not being generalization; generalization is framed as discovering multiple solutions and selecting the best. [Unverified]

## LLMs and Scientific Validity (Claims)

- LLMs are framed as unsuitable for scientific purposes because their training priors are unknown (vast, uncontrolled datasets), making controlled experimentation difficult/impossible. [Unverified]

## Human-in-the-Loop Framing (Claims)

- LLM improvements in coding abstraction/architecture are framed as stemming from human involvement in the process rather than algorithms inherently promoting generalization. [Unverified]

