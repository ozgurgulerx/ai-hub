# vLLM Overview

Collect setup notes, batching strategies, and tuning guides here. Pull highlights from your `day-XXX` logs so this stays concise and actionable.

## Quick links

- 2025 roadmap/architecture notes (talk summary): `state-of-vllm-2025-ray-summit.md`
- Runtime probes journal day (kernel timelines, bottlenecks): `../../days/day-007-vllm-runtime-probes/`

## Setup & operations (TODO)

- Installation and environment tips
- Preferred models / formats
- Serving configuration defaults

## Performance tuning (TODO)

- Batching / paged attention sweet spots
- Prefill vs decode bottlenecks
- When vLLM is a fit vs TensorRT-LLM / Triton
