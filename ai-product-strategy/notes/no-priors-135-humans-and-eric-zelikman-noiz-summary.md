# No Priors Ep. 135 (humans& / Eric Zelikman) — Notes

Summary for: https://youtu.be/Oh0oQnKn9dw  
Generated from subtitles tooling (Noiz): https://noiz.io/tools/youtube-subtitles  
Status: **To verify**

## Human-Centric AI (Thesis)

- “Jagged intelligence” is emphasized: models can solve complex tasks but fail on tricky assumptions and lack emotional intelligence (EQ) for underlying human goals. [Unverified]
- Systems that collaborate with people over time (considering implications of interactions) are framed as solving human problems better than short, isolated “answer” interactions. [Unverified]

## Memory and Context Integration

- Long-term memory is framed as enabling fundamentally different collaboration: remembering and integrating information about a person over time so users don’t re-explain context every time. [Unverified]
- More context is described as helping closed-form/verifiable tasks, but models still struggle with out-of-distribution and non-verifiable tasks. [Unverified]
- Understanding user goals/values/weaknesses over time is framed as reducing harmful effects (e.g., hallucinations) by treating interactions as connected rather than independent tasks. [Unverified]

## Human Agency vs “Remove the Human”

- It’s framed as an active design decision whether to scale AI with people in the loop vs remove people; removing humans reduces human input in what gets built and reduces agency/understanding of outputs. [Unverified]

## Market Growth Through Empowerment

- Empowering people (not just replacing tasks) is framed as expanding the market: models that understand goals/ambitions/values can help people accomplish what they want. [Unverified]

## Building humans& (Company Framing)

- humans& is framed as building EQ-driven, long-term-collaboration AI with memory integration and new interaction modes, with emphasis on “beautiful, tasteful products.” [Unverified]
- Q‑STaR is mentioned as a reasoning algorithm; it’s described as scaling to pre-training level using pre-training-style data and using an online curriculum where harder problems provide more learning signal. [Unverified]

## Related (In This Repo)

- Agent notes index (memory, workflows): `../../projects/agents/notes/README.md`
- Reasoning + verification dependence (Jason Wei/Denny Zhou): `../../model-space/reasoning-models/README.md`

