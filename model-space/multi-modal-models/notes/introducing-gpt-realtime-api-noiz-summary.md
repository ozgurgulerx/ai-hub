# Introducing GPT Realtime in the API — Notes

Summary for: https://youtu.be/nfBbmtMJhX0  
Generated from subtitles tooling (Noiz): https://noiz.io/tools/youtube-subtitles  
Status: **To verify**

## Model Capability (Speech-to-Speech)

- GPT Realtime is described as a single model that natively understands and produces audio, capturing nuances (e.g., laughter/sighs), expressing a range of emotions, and switching languages mid-sentence.
- Instruction following is described as more steerable for voice apps (pace, tone, style, roleplay characters) across multi-turn conversations.

## Customer-Centric Training (Claim)

- The model is described as trained in close collaboration with customers building production voice apps, aligned for scenarios like customer support and academic tutoring.

## API / Platform Capabilities (Claims)

- The real-time API is described as targeting low-latency voice applications at scale, with improved latency/reliability.
- Additional capabilities mentioned: image input, EU data residency, and asynchronous function calling.

## Tools / Pluggable Capabilities (MCP Mention)

- “MCP (pluggable capabilities)” is described as enabling custom capabilities, working well with voice: interpret audio → take action through tools → interact naturally.

## Function Calling (Claim + Metric)

- Function calling is described as smarter (choosing functions + passing correct arguments).
- A metric is cited: 66% accuracy on “complex phone bench audio evaluations” (verify definition/benchmark).

