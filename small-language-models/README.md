# Small Language Models (SLMs)

Notes and building guides for **small language models**: compact LMs (often framed as “< 1B parameters”) that trade peak capability for lower latency/cost and easier deployment.

## What’s Here

- Build an SLM from scratch (TinyStories + GPT-2 tokenizer + nanoGPT-style pipeline): `notes/build-slm-from-scratch-tinystories.md`

## Related (In This Repo)

- Inference & serving tradeoffs: `../inference-engineering/README.md`
- Continual updates / distillation patterns: `../reinforcement-learning/continual-learning/README.md`
- Retrieval + grounding to cover knowledge gaps: `../retrieval-augmented-systems/README.md`
