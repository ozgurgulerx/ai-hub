# ai-security-and-governance

My work on AI security methods and everything on AI security.

## Day001

- Checklist + commands: `docs/day001/checklist.md`
- Threat matrix: `docs/day001/threat-matrix.md`
- Optional red teaming tools (garak + PyRIT): `docs/day001/red-teaming-tools.md`

## Docs (Index)

- Start here: `docs/README.md`

## Privacy-preserving ML (P1)

- Overview: `docs/privacy/README.md`
- Federated learning: `../docs/ai-security-and-governance/privacy/federated-learning.md`
- Differential privacy: `../docs/ai-security-and-governance/privacy/differential-privacy.md`

## What AI Security Implies

AI security covers the ways AI systems can be attacked, misused, or fail, and the methods to reduce those risks. This includes:
- Adversarial and data poisoning attacks.
- Model theft, extraction, and inversion.
- Prompt injection and tool misuse.
- Privacy, data leakage, and sensitive information exposure.
- Robustness, monitoring, and incident response for AI systems.
- Governance, compliance, and secure deployment practices.

## AI Governance

AI governance is how organizations turn **responsible AI principles** into **enforceable controls** across the AI lifecycle (policies, roles, risk management, evaluations, monitoring, incident response, and audit evidence).

- Read: `docs/ai-governance/README.md`

## MCP Security

Security considerations for systems using the Model Context Protocol (MCP): trust boundaries, common failure modes, and concrete controls.

- Read: `docs/mcp-security/README.md`

## Agent Governance

Agent governance is the set of controls and operating practices for **AI agents that take actions via tools/APIs** (not just generate text). It bridges security, safety, and operational reliability:

- Read: `docs/agent-governance/README.md`

## Papers

- (Add papers here)
