# AI Safety for Everyone (Atoosa Kasirzadeh) — Notes

Summary for: https://youtu.be/DpPiv_Lzokg  
Generated from transcript tooling (Noiz): https://noiz.io/tools/youtube-transcript  
Status: **To verify**

## Reframing “AI Safety” Beyond Existential Risk

- AI safety is described as covering a broad set of concerns across development and deployment (present-day risks included), based on a systematic review of peer-reviewed literature (as referenced).
- AI safety is framed as a continuation of **engineering safety** for AI systems (technical safety as a technology), not exclusively existential-risk focused.
- The scope described includes undesirable behavior, adversarial attacks, and objective misalignment in current systems.

## Practical Barriers (Adoption / Incentives)

- Framing safety as only existential risk is described as creating resistance among some builders/investors and excluding practitioners approaching safety from different angles.
- A proposed approach is to ground safety research in engineering safety to reduce terminology-driven divisions (as described).

## Sociotechnical Nature

- AI safety is described as sociotechnical: deployment context and societal impact are part of the risk surface, so “technical vs sociotechnical” separation can be misleading.

## Present-Day, Empirical Focus

- Emphasis on improving safety of currently deployed systems via best practices and empirical observation.
- Example cited: real-world interactions can surface previously unknown risks (e.g., chatbots inducing harmful psychological outcomes).

